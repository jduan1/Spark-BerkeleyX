{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    word|\n",
      "+--------+\n",
      "|     cat|\n",
      "|elephant|\n",
      "|     rat|\n",
      "|     rat|\n",
      "|     cat|\n",
      "+--------+\n",
      "\n",
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- word: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDF = sqlContext.createDataFrame([('cat',), ('elephant',), ('rat',), ('rat',), ('cat', )], ['word'])\n",
    "wordsDF.show()\n",
    "print(type(wordsDF))\n",
    "wordsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|    word|\n",
      "+--------+\n",
      "|     cat|\n",
      "|elephant|\n",
      "|     rat|\n",
      "|     rat|\n",
      "|     cat|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|     cats|\n",
      "|elephants|\n",
      "|     rats|\n",
      "|     rats|\n",
      "|     cats|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, concat\n",
    "pluralDF = wordsDF.select(concat(wordsDF.word, lit('s')).alias('word'))\n",
    "pluralDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|length(word)|\n",
      "+------------+\n",
      "|           4|\n",
      "|           9|\n",
      "|           4|\n",
      "|           4|\n",
      "|           4|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import length\n",
    "pluralLengthsDF = pluralDF.select(length(pluralDF.word))\n",
    "pluralLengthsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|     rat|    2|\n",
      "|     cat|    2|\n",
      "|elephant|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordCountsDF = (wordsDF\n",
    "                .groupBy(wordsDF.word)\n",
    "                .count()\n",
    ")\n",
    "wordCountsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "uniqueWordsCount = wordCountsDF.count()\n",
    "print(uniqueWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.66666666667\n"
     ]
    }
   ],
   "source": [
    "averageCount = wordCountsDF.groupBy().mean().head()[0]\n",
    "#wordCountsDF.groupBy().select(mean().alias(\"count\"))\n",
    "print(averageCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|    word|count|\n",
      "+--------+-----+\n",
      "|     rat|    2|\n",
      "|     cat|    2|\n",
      "|elephant|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def wordCount(wordListDF):\n",
    "    return wordListDF.groupBy(wordListDF.word).count()\n",
    "wordCount(wordsDF).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|sentence                                    |\n",
      "+--------------------------------------------+\n",
      "|Hi, you!                                    |\n",
      "| No under_score                             |\n",
      "| *      Remove punctuation and spaces   *   |\n",
      "+--------------------------------------------+\n",
      "\n",
      "+-----------------------------+\n",
      "|sentence                     |\n",
      "+-----------------------------+\n",
      "|hi you                       |\n",
      "|no underscore                |\n",
      "|remove punctuation and spaces|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace, trim, col, lower\n",
    "def removePunctuation(column):\n",
    "    return trim(regexp_replace(lower(column), '[^0-9a-z\\s]', '')).alias('sentence')\n",
    "\n",
    "sentenceDF = sqlContext.createDataFrame([('Hi, you!',),\n",
    "                                         (' No under_score',),\n",
    "                                         (' *      Remove punctuation and spaces   *   ',),\n",
    "                                        ],['sentence'])\n",
    "sentenceDF.show(truncate=False)\n",
    "(sentenceDF\n",
    " .select(removePunctuation(col('sentence')))\n",
    " .show(truncate=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|sentence                                         |\n",
      "+-------------------------------------------------+\n",
      "|1609                                             |\n",
      "|                                                 |\n",
      "|the sonnets                                      |\n",
      "|                                                 |\n",
      "|by william shakespeare                           |\n",
      "|                                                 |\n",
      "|                                                 |\n",
      "|                                                 |\n",
      "|1                                                |\n",
      "|from fairest creatures we desire increase        |\n",
      "|that thereby beautys rose might never die        |\n",
      "|but as the riper should by time decease          |\n",
      "|his tender heir might bear his memory            |\n",
      "|but thou contracted to thine own bright eyes     |\n",
      "|feedst thy lights flame with selfsubstantial fuel|\n",
      "+-------------------------------------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fileName = '100.txt.utf-8'\n",
    "shakespeareDF = sqlContext.read.text(fileName).select(removePunctuation(col('value')))\n",
    "shakespeareDF.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|       word|\n",
      "+-----------+\n",
      "|       1609|\n",
      "|        the|\n",
      "|    sonnets|\n",
      "|         by|\n",
      "|    william|\n",
      "|shakespeare|\n",
      "|          1|\n",
      "|       from|\n",
      "|    fairest|\n",
      "|  creatures|\n",
      "|         we|\n",
      "|     desire|\n",
      "|   increase|\n",
      "|       that|\n",
      "|    thereby|\n",
      "|    beautys|\n",
      "|       rose|\n",
      "|      might|\n",
      "|      never|\n",
      "|        die|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "902553\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split, explode\n",
    "shakeWordsDF = (shakespeareDF\n",
    "                .select(explode(split(shakespeareDF.sentence, ' ')).alias('word'))\n",
    "                .where(col('word') != ''))\n",
    "shakeWordsDF.show()\n",
    "shakeWordsDFCount = shakeWordsDF.count()\n",
    "print(shakeWordsDFCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "|the |27776|\n",
      "|and |26755|\n",
      "|i   |20681|\n",
      "|to  |19235|\n",
      "|of  |18246|\n",
      "|a   |14653|\n",
      "|you |13685|\n",
      "|my  |12481|\n",
      "|that|11123|\n",
      "|in  |11018|\n",
      "|is  |9601 |\n",
      "|not |8736 |\n",
      "|for |8239 |\n",
      "|with|8037 |\n",
      "|me  |7769 |\n",
      "|it  |7690 |\n",
      "|be  |7096 |\n",
      "|your|6882 |\n",
      "|this|6868 |\n",
      "|his |6857 |\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "topWordsAndCountsDF = wordCount(shakeWordsDF)\n",
    "topWordsAndCountsDF.orderBy(col('count').desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      word|count|\n",
      "+----------+-----+\n",
      "|       art|  915|\n",
      "|      some| 1338|\n",
      "|     those|  546|\n",
      "|     still|  552|\n",
      "|  painters|    1|\n",
      "|      hope|  355|\n",
      "|    travel|   33|\n",
      "|     cures|    8|\n",
      "|    ransom|   53|\n",
      "|     spoil|   25|\n",
      "|   tresses|    3|\n",
      "|       few|   66|\n",
      "| forgetful|    5|\n",
      "|    harder|   11|\n",
      "|  tripping|    6|\n",
      "| soundness|    1|\n",
      "|    waters|   27|\n",
      "|occidental|    1|\n",
      "|    marrow|    4|\n",
      "|    distil|    4|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topWordsAndCountsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
